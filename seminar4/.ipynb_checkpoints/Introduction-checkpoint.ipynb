{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# fMRI data preprocessing - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adasegroup/NEUROML2020/blob/seminar4/seminar-4/Introduction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "fMRI scans are saved in dicom format. For scientific analysis of brain images the nifty format (.nii files) are often used.\n",
    "The conversion from dicom to nifty can be done with [dcm2niix](https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage#Introduction) \n",
    "\n",
    "Many file are generated during fMRI sessions. These can arranged in many ways, thus a standard is needed how to arrange them. \n",
    "Commonly used standard is [Brain Imaging Data Structure (BIDS)](https://bids.neuroimaging.io/).\n",
    "\n",
    "You can use [HeuDiConv](https://heudiconv.readthedocs.io/en/latest/) or [Dcm2Bids](https://cbedetti.github.io/Dcm2Bids/tutorial/) to automate the conversion from dicom to BIDS.\n",
    "\n",
    "![DICOM TO BIDS](https://www.incf.org/sites/default/files/articles/bids_standard-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's download the data we will be working with. We will download data through DataLad. It's destibuted data managements system, its provide data storage and version control.\n",
    "\n",
    "http://www.datalad.org/ \n",
    "\n",
    "about the data, that we working with:\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3641991/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "datalad get -J 4 -d /data/ds000114 \\\n",
    "    /data/ds000114/derivatives/fmriprep/sub-*/anat/*preproc.nii.gz \\\n",
    "    /data/ds000114/sub-*/ses-test/func/*fingerfootlips*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from utils import list_files\n",
    "# The data is already in BIDS format\n",
    "# The subjects peformed 5 tasks. We will focus on fingerfootlips task\n",
    "list_files('/data/ds000114/sub-01/ses-retest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With nibabel we can load a file and inspect its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import nibabel\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "anat = nibabel.load('/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz')\n",
    "fmri = nibabel.load('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz')\n",
    "\n",
    "print(f'Anatomical dimensionality is {anat.ndim} and fmri is {fmri.ndim}')\n",
    "#The anatomical image have higher resolution then the fmri\n",
    "print(f'Anatomical voxelization: {anat.shape}\\nfMRI voxelization: {fmri.shape}')\n",
    "#the data can be accessed as\n",
    "print(f'\\nAnatomical volume affine:\\n{anat.affine}\\nfMRI affine:\\n{fmri.affine}')\n",
    "data = np.array(anat.dataobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets stop on SliceTiming key, unlike a photograph, in which the entire picture is taken in a single moment, an fMRI volume is acquired in slices. Each of these slices takes time to acquire - from tens to hundreds of milliseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The two most commonly used methods for creating volumes are sequential and interleaved slice acquisition. Sequential slice acquisition acquires each adjacent slice consecutively, either bottom-to-top or top-to-bottom. Interleaved slice acquisition acquires every other slice, and then fills in the gaps on the second pass. Both of these methods are illustrated in the video below.\n",
    "\n",
    "https://www.brainvoyager.com/bv/doc/UsersGuide/Preprocessing/SliceScanTimeCorrection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SliceTiming](https://andysbrainbook.readthedocs.io/en/latest/_images/SliceTimingCorrection_Demo.gif \"slicetiming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#metadata is located in json files\n",
    "with open('/data/ds000114/task-fingerfootlips_bold.json', 'rt') as fp:\n",
    "    task_info = json.load(fp)\n",
    "task_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(task_info['SliceTiming'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction Nipype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Why nipype?**\n",
    "\n",
    "Nipype allows to build preprocessing pipelines from different softwares, and it is computationally efficient. There are some helpful ready to use pipleines written with Nipype like [fmriprep](https://fmriprep.org/en/stable/index.html). To use fmriprep the data have to be in valid BIDS format. The user have to supply only the path to the data setup the [parametars](https://fmriprep.org/en/stable/usage.html#command-line-arguments). \n",
    "\n",
    "In Nipype, interfaces are python modules that allow you to use various external packages (e.g. FSL, SPM or FreeSurfer), even if they themselves are written in another programming language than python. Such an interface knows what sort of options an external program has and how to execute it.\n",
    "\n",
    "![Nipype architecture](https://raw.github.com/satra/intro2nipype/master/images/arch.png)\n",
    "\n",
    "In Nipype, a node is an object that executes a certain function. This function can be anything from a Nipype interface to a user-specified function or an external script. Each node consists of a name, an interface category and at least one input field, and at least one output field.\n",
    "\n",
    "\n",
    "Once you connect multiple nodes to each other, you create a directed graph. In Nipype we call such graphs either workflows or pipelines. Directed connections can only be established from an output field of a node to an input field of another node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nipype import Node, Function, Workflow\n",
    "from IPython.display import Image, clear_output\n",
    "\n",
    "\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "#Create a Node that multiplies 2 numbers\n",
    "mul = Node(Function(input_names=['a', 'b'],\n",
    "                      output_names=['multiply_result'],\n",
    "                      function=multiply), \n",
    "             name='a_x_b')\n",
    "\n",
    "mul.inputs.a = 2\n",
    "mul.inputs.b = 3\n",
    "\n",
    "result = mul.run()\n",
    "result.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Create a Node that adds 2 numbers\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "\n",
    "adder = Node(Function(input_names=['a', 'b'],\n",
    "                      output_names=['add'],\n",
    "                      function=add), \n",
    "             name='a_plus_b')\n",
    "adder.inputs.b = 10\n",
    "\n",
    "#Create a workflow \n",
    "wf = Workflow('hello')\n",
    "# connect the nodes \n",
    "wf.connect(mul, 'multiply_result', adder, 'a')\n",
    "#visualize the graph\n",
    "wf.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "clear_output()\n",
    "Image(filename='graph_detailed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#run the graph\n",
    "eg = wf.run()\n",
    "clear_output()#don't print the pipeline steps during exection\n",
    "#check the results\n",
    "eg = list(eg.nodes())\n",
    "nodes_outputs = [node.result.outputs for node in eg]\n",
    "nodes_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Dataset:**\n",
    "[A test-retest fMRI dataset for motor, language and spatial attention functions](https://openneuro.org/datasets/ds000114/versions/1.0.1)\n",
    "\n",
    "**About nipype**\n",
    "https://www.frontiersin.org/articles/10.3389/fninf.2011.00013/full\n",
    "\n",
    "**Thanks to Michael Notter for the wonderful [nipype tutorial](https://miykael.github.io/nipype_tutorial/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
