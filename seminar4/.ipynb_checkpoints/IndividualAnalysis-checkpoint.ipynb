{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GLM: 1st-level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The objective in this example is to model the timecourse of each voxel. This will allow us to answer question regarding to the voxel response to different stimuli. \n",
    "\n",
    "We will model the activation at each voxel $y$ as a weighed sum of explanatory variables $x_{i}$ \n",
    "and error term ${\\epsilon}$\n",
    "\n",
    "$${y} = {\\beta}_{0} + \\sum \\limits _{i=1} ^{N} x_{i}{\\beta}_{i} + {\\epsilon} $$\n",
    "\n",
    "or in matrix notation\n",
    "\n",
    "$$ y = {\\beta} X + {\\epsilon} $$\n",
    "\n",
    "which can be solved with Ordinary Least Squares regression.\n",
    "\n",
    "The parameters ${\\beta}$ represent the contribution of each variable to the voxel activation.\n",
    "\n",
    "The error terms are assumed to be independent and identically distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Design matrix](https://mri-q.com/uploads/3/4/5/7/34572113/9355842_orig.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The matrix  ð‘‹  is also called design matrix.It is up to the researcher which factors to include in the design matrix. The design matrix contains factors that a related to the hypothesis the researcher want to answer. Furthermore, sometimes in it are also included factors that are not related to the hypothesis, but are know sources of variability (nuisance factors).\n",
    "\n",
    "Now lets take a look how we take into account the delayed bold response.\n",
    "The hemodynamic response function might look something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def hrf(t):\n",
    "    return t ** 8.6 * np.exp(-t / 0.547)\n",
    "\n",
    "hrf_times = np.arange(0, 20, 0.1)\n",
    "hrf_signal = hrf(hrf_times)\n",
    "plt.plot(hrf_times, hrf_signal)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('BOLD signal')\n",
    "_ = plt.title('HRF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the design often we want to include variables, that indicate presence or absence of a stimuli.\n",
    "Let's say we had the 3 stimuli during the timecourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n_time_points = 40\n",
    "\n",
    "times = np.arange(0, n_time_points)  \n",
    "\n",
    "neural_signal = np.zeros(n_time_points)\n",
    "neural_signal[4:6] = 1  # A 3 second event\n",
    "neural_signal[9:11] = 1\n",
    "neural_signal[22:24] = 1\n",
    "\n",
    "plt.plot(times, neural_signal)\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('neural signal')\n",
    "plt.ylim(0, 3.2)\n",
    "_ = plt.title('Neural model for three impulses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next we have to convolve signal with our hrf function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hrf_times = np.arange(20)\n",
    "hrf_signal = hrf(hrf_times)\n",
    "bold_signal = np.convolve(neural_signal, hrf_signal)\n",
    "\n",
    "tailed_respose_times = np.arange(n_time_points + hrf_times.shape[0] - 1)\n",
    "plt.plot(tailed_respose_times, bold_signal)\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('bold signal')\n",
    "_ = plt.title('Convolved signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After that we can fit our fMRI data to the design Matrix and use GLM to for hypotesis testing.\n",
    "We can evaluate whether a given factor $i$ has a considerable contribution by its coefficient ${\\beta}_{i}$.\n",
    "With t-test we can evaluate whether ${\\beta}_{i}$ > 0. We can also test hypothesis of the form ${\\beta}_{i}$ > ${\\beta}_{j}$.\n",
    "\n",
    "The general form of the hypothesis tests which forms a **contrast** is:\n",
    "$$\\sum \\limits _{i=1} ^{P} c_{i}{\\beta}_{i} > 0 $$\n",
    "\n",
    "Typical values for $c$ are 1 and -1.\n",
    "Typically contrasts are express as:$ [c_{1}, c_{2}, ..., c_{N}]$.\n",
    "\n",
    "For example the contrast [1, 0] tests ${\\beta}_{1}$ > 0.\n",
    "\n",
    "This contrasts form a t-statistics (Recall that coefficient/std(coefficient) in OLS regression follow t-distribution with n-p-1 df).\n",
    "\n",
    "We can combine several contrasts and form F-statics. In the contexts of fMRI the F-tests help us answer questions like \"Is effect A or effect B or effect C, or any combination of them, significantly non-zero?\".\n",
    "\n",
    "Recall that F test is used for comparison between reduced model RF and full model FM:\n",
    "$$ F = \\frac{(SSE(RM)-SSR(FM)) /(p+1-k))}{SSE(FM)/(n-p-1)} $$\n",
    "\n",
    "where the reduced model have k distinct parameters\n",
    "\n",
    "\n",
    "Combining the test results from all voxels we get statistical map of brain activity.\n",
    "Now that the theory out of our way we can see how it is done in Nipype.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1st Leval Analysis in Nipype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " We will use the preprocessed files we got and run 1st-level analysis (individual analysis) for each subject. We will perform the following steps:\n",
    "\n",
    "1. Extract onset times of stimuli from TVA file\n",
    "2. Specify the model (TR, high pass filter, onset times, etc.)\n",
    "3. Specify contrasts to compute\n",
    "4. Estimate contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from nipype.interfaces.spm import Level1Design, EstimateModel, EstimateContrast\n",
    "from nipype.algorithms.modelgen import SpecifySPMModel\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype import Workflow, Node\n",
    "from utils import list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# specify paths\n",
    "experiment_dir = '/output'\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers\n",
    "subject_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n",
    "# Repetition time(TR) of functional images\n",
    "TR = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prepare design matrix\n",
    "Let's take a look how the stimuli onset and duration look like.This information is store in a ``tsv`` file. This file will help us build the design matrix.\n",
    "\n",
    "The three different conditions in the **fingerfootlips** task are:\n",
    "- **finger**\n",
    "- **foot**\n",
    "- **lips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trialinfo = pd.read_table('/data/ds000114/task-fingerfootlips_events.tsv')\n",
    "trialinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def subjectinfo(subject_id):\n",
    "    import pandas as pd\n",
    "    from nipype.interfaces.base import Bunch\n",
    "\n",
    "    \n",
    "    trialinfo = pd.read_table('/data/ds000114/task-fingerfootlips_events.tsv')\n",
    "    #trialinfo.head()\n",
    "    conditions = []\n",
    "    onsets = []\n",
    "    durations = []\n",
    "\n",
    "    for group in trialinfo.groupby('trial_type'):\n",
    "        conditions.append(group[0])\n",
    "        onsets.append(list(group[1].onset - 10)) # subtracting 10s due to removing of 4 dummy scans\n",
    "        durations.append(group[1].duration.tolist())\n",
    "\n",
    "    subject_info = [Bunch(conditions=conditions,\n",
    "                          onsets=onsets,\n",
    "                          durations=durations\n",
    "                         )]\n",
    "\n",
    "    return subject_info  # this output will later be returned to infosource\n",
    "\n",
    "# Get Subject Info - get subject specific condition information\n",
    "getsubjectinfo = Node(Function(input_names=['subject_id'],\n",
    "                               output_names=['subject_info'],\n",
    "                               function=subjectinfo),\n",
    "                      name='getsubjectinfo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initiate Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# SpecifyModel - Generates SPM-specific Model\n",
    "#Setup\n",
    "#https://nipype.readthedocs.io/en/latest/api/generated/nipype.algorithms.modelgen.html#specifymodel\n",
    "modelspec = Node(SpecifySPMModel(concatenate_runs=False,\n",
    "                                 input_units='secs',\n",
    "                                 output_units='secs',\n",
    "                                 time_repetition=TR,\n",
    "                                 high_pass_filter_cutoff=128),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# Level1Design - Generates an SPM design matrix\n",
    "#https://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf#page=59\n",
    "#hrf- Name of basis function(canonical)\n",
    "#'derivs': [1, 0]-Time derivatives : Time and Dispersion\n",
    "\n",
    "#model_serial_correlations-serial correlations using an autoregressive estimator (order 1)\n",
    "\n",
    "level1design = Node(Level1Design(bases={'hrf': {'derivs': [1, 0]}},\n",
    "                                 timing_units='secs',\n",
    "                                 interscan_interval=TR,\n",
    "                                 model_serial_correlations='AR(1)'),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# EstimateModel - estimate the parameters of the model\n",
    "#https://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf#page=69\n",
    "\n",
    "level1estimate = Node(EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level1estimate\")\n",
    "\n",
    "# EstimateContrast - estimates contrasts\n",
    "level1conest = Node(EstimateContrast(), name=\"level1conest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specify contrasts\n",
    "We are gona perform several T tests and one F test. Recall the general form of the hypothesis are\n",
    "\n",
    "$$\\sum \\limits _{i=1} ^{N} c_{i}{\\beta}_{i} > 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Condition names\n",
    "condition_names = ['Finger', 'Foot', 'Lips']\n",
    "\n",
    "# Contrasts\n",
    "# contrast =  [<contrast_name>, <test>, <condition_names>, <[c1, c2, c3]>]\n",
    "cont01 = ['average',        'T', condition_names, [1/3., 1/3., 1/3.]]\n",
    "cont02 = ['Finger',         'T', condition_names, [1, 0, 0]]\n",
    "cont03 = ['Foot',           'T', condition_names, [0, 1, 0]]\n",
    "cont04 = ['Lips',           'T', condition_names, [0, 0, 1]]\n",
    "cont05 = ['Foot > others',  'T', condition_names, [-0.5, 1, -0.5]]\n",
    "cont06 = ['activation',     'F', [cont02, cont03, cont04]]\n",
    "\n",
    "contrast_list = [cont01, cont02, cont03, cont04, cont05, cont06]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specify input & output stream\n",
    "\n",
    "Specify where the input data can be found & where and how to save the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id',\n",
    "                                            'contrasts'],\n",
    "                                    contrasts=contrast_list),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "templates = {\n",
    "        'func': 'datasink/preproc/sub-{subject_id}/task-{task_id}/fwhm-5_ssub-{subject_id}_ses-test_task-{task_id}_bold.nii',\n",
    "        'mc_param': 'datasink/preproc/sub-{subject_id}/task-{task_id}/sub-{subject_id}_ses-test_task-{task_id}_bold.par',\n",
    "        'outliers': 'datasink/preproc/sub-{subject_id}/task-{task_id}/art.sub-{subject_id}_ses-test_task-{task_id}_bold_outliers.txt'\n",
    "    }\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory=experiment_dir,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")\n",
    "selectfiles.inputs.task_id = 'fingerfootlips'\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', 'sub-')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specify Workflow\n",
    "\n",
    "Create a workflow and **connect** the interface nodes and the I/O stream to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initiation of the 1st-level analysis workflow\n",
    "l1analysis = Workflow(name='l1analysis')\n",
    "l1analysis.base_dir = f'{experiment_dir}/{working_dir}'\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "l1analysis.connect([(infosource, selectfiles, [('subject_id', 'subject_id')]),\n",
    "                    (infosource, getsubjectinfo, [('subject_id',\n",
    "                                                   'subject_id')]),\n",
    "                    (getsubjectinfo, modelspec, [('subject_info',\n",
    "                                                  'subject_info')]),\n",
    "                    (infosource, level1conest, [('contrasts', 'contrasts')]),\n",
    "                    (selectfiles, modelspec, [('func', 'functional_runs')]),\n",
    "                    (selectfiles, modelspec, [('mc_param', 'realignment_parameters'),\n",
    "                                              ('outliers', 'outlier_files')]),\n",
    "                    (modelspec, level1design, [('session_info',\n",
    "                                                'session_info')]),\n",
    "                    (level1design, level1estimate, [('spm_mat_file',\n",
    "                                                     'spm_mat_file')]),\n",
    "                    (level1estimate, level1conest, [('spm_mat_file',\n",
    "                                                     'spm_mat_file'),\n",
    "                                                    ('beta_images',\n",
    "                                                     'beta_images'),\n",
    "                                                    ('residual_image',\n",
    "                                                     'residual_image')]),\n",
    "                    (level1conest, datasink, [('spm_mat_file', '1stLevel.@spm_mat'),\n",
    "                                              ('spmT_images', '1stLevel.@T'),\n",
    "                                              ('con_images', '1stLevel.@con'),\n",
    "                                              ('spmF_images', '1stLevel.@F'),\n",
    "                                              ('ess_images', '1stLevel.@ess'),\n",
    "                                              ]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save the 1st-level analysis graph as png\n",
    "l1analysis.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=f'{l1analysis.base_dir}/l1analysis/graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# show detailed workflow\n",
    "l1analysis.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "Image(filename=f'{l1analysis.base_dir}/l1analysis/graph_detailed.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Run the Workflow\n",
    "\n",
    "Run the 1st-level analysis workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "l1analysis.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crashs information is stored in .pklz files\n",
    "# In case of a crash use the following command\n",
    "#!nipypecli crash <Last generated .pklz file>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspect output\n",
    "\n",
    "Let's check the structure of the output folder, to see if we have everything we wanted to save. You should one image for each subject and contrast (``con_*.nii`` for T-contrasts and ``ess_*.nii`` for F-contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!tree /output/datasink/1stLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize results\n",
    "\n",
    "Let's look at the contrasts of one subject that we've just computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "\n",
    "#Reminder the tests were \n",
    "test_to_number = {\n",
    "    1: 'average',\n",
    "    2: 'Finger',\n",
    "    3: 'Foot',\n",
    "    4: 'Lips',\n",
    "    5: 'Foot > others',\n",
    "    6: 'activation'\n",
    "    }\n",
    "subject_id = '01'\n",
    "anatimg = f'/data/ds000114/derivatives/fmriprep/sub-{subject_id}/anat/sub-{subject_id}_t1w_preproc.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "subject_id = '01'\n",
    " \n",
    "anatimg = f'/data/ds000114/derivatives/fmriprep/sub-{subject_id}/anat/sub-{subject_id}_t1w_preproc.nii.gz'\n",
    "for contrast_id in range(1, 6):\n",
    "    plot_stat_map(\n",
    "        f'/output/datasink/1stLevel/sub-{subject_id}/spmT_000{contrast_id}.nii', title=test_to_number[contrast_id],\n",
    "        bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "contrast_id = 6\n",
    "subject_id = '01'\n",
    "\n",
    "plot_stat_map(\n",
    "        f'/output/datasink/1stLevel/sub-{subject_id}/spmF_000{contrast_id}.nii', title=test_to_number[contrast_id],\n",
    "        bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sources:**\n",
    "\n",
    "\n",
    "[General Linear Model for Neuroimaging](https://www.fmrib.ox.ac.uk/primers/appendices/glm.pdf)\n",
    "\n",
    "[Convolution](https://practical-neuroimaging.github.io/on_convolution.html)\n",
    "\n",
    "[General Linear Model (GLM)](http://mriquestions.com/general-linear-model.html)\n",
    "\n",
    "\n",
    "**Special thanks to Michael Notter for the wonderful [nipype tutorial](https://miykael.github.io/nipype_tutorial/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
