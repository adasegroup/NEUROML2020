{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Group Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We often want to generalize the results from our experiment to out of sample data. Here we will infer from the individual \n",
    "subjects activation maps to one activation map for all subjects.\n",
    "\n",
    "To do this the following steps must be done:\n",
    "\n",
    "**1. Normalize the subjects data to a common space**\n",
    "\n",
    "**2. Build a second level GLM**\n",
    "\n",
    "**3. Hypothesis testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Group Analysis](https://s3.studylib.net/store/data/008208763_1-08a21265815c4e2c11a8b6effd90bfa3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The second level GLM has the form\n",
    "$$ {\\beta}= {\\beta}_g X_g + {\\eta} $$\n",
    "\n",
    "where:\n",
    "\n",
    "$X_g$ - new design matrix\n",
    "\n",
    "${\\beta}$ - estimated from 1st level\n",
    "\n",
    "\n",
    "Then we can find ${\\beta}_g$ and perform hypothesis testing on it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalize data to MNI template\n",
    "\n",
    "\n",
    "We will take the computed 1st-level contrasts from the previous experiment  and normalize them into MNI-space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Preparation\n",
    "\n",
    "We first need to download the already computed deformation field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "datalad get -J 4 -d /data/ds000114 /data/ds000114/derivatives/fmriprep/sub-0[2345789]/anat/*h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Alternatively: Prepare yourself\n",
    "We're using the precomputed warp field from [fmriprep](http://fmriprep.readthedocs.io), as this step otherwise would take up too much time. If you're nonetheless interested in computing the warp parameters with ANTs yourself, without using [fmriprep](http://fmriprep.readthedocs.io), either check out the script [ANTS_registration.py](https://github.com/miykael/nipype_tutorial/blob/master/notebooks/scripts/ANTS_registration.py) or even quicker, use [RegistrationSynQuick](http://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.ants/registration.html#registrationsynquick), Nipype's implementation of `antsRegistrationSynQuick.sh`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalization with ANTs\n",
    "\n",
    "The normalization with ANTs requires that you first compute the transformation matrix that would bring the anatomical images of each subject into template space. Depending on your system this might take a few hours per subject. To facilitate this step, the transformation matrix is already computed for the T1 images.\n",
    "\n",
    "The data for it can be found under:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!ls /data/ds000114/derivatives/fmriprep/sub-*/anat/*h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Now, let's start with the ANTs normalization workflow!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Imports\n",
    "\n",
    "First, we need to import all the modules we later want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import join as opj\n",
    "from nipype import Workflow, Node, MapNode\n",
    "from nipype.interfaces.ants import ApplyTransforms\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.interfaces.fsl import Info\n",
    "\n",
    "\n",
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "from nipype.interfaces.spm import (OneSampleTTestDesign, EstimateModel,\n",
    "                                   EstimateContrast, Threshold)\n",
    "\n",
    "from nipype.algorithms.misc import Gunzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Experiment parameters\n",
    "\n",
    " We will run the group analysis without subject ``sub-01``, ``sub-06`` and ``sub-10`` because they are left-handed.\n",
    "\n",
    "This is because all subjects were asked to use their dominant hand, either right or left. There were three subjects (``sub-01``, ``sub-06`` and ``sub-10``) that were left-handed.\n",
    "\n",
    "**Because of this, We will use only right-handed subjects for the following anlysis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "experiment_dir = '/output'\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers (remember we use only right handed subjects)\n",
    "subject_list = ['02', '03', '04', '05', '07', '08', '09']\n",
    "\n",
    "# task name\n",
    "task_name = \"fingerfootlips\"\n",
    "number_contrasts = 5 # number of contrast from 1stlevel\n",
    "\n",
    "\n",
    "# Template to normalize to\n",
    "template = '/data/ds000114/derivatives/fmriprep/mni_icbm152_nlin_asym_09c/1mm_T1.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specify Nodes\n",
    "\n",
    "Initiate ANTs interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Apply Transformation - applies the normalization matrix to contrast images\n",
    "apply2con = MapNode(ApplyTransforms(args='--float',\n",
    "                                    input_image_type=3,\n",
    "                                    interpolation='BSpline',\n",
    "                                    invert_transform_flags=[False],\n",
    "                                    num_threads=1,\n",
    "                                    reference_image=template,\n",
    "                                    terminal_output='file'),\n",
    "                    name='apply2con', iterfield=['input_image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specify input & output stream\n",
    "\n",
    "Specify where the input data can be found & where and how to save the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "templates = {'con': opj(output_dir, '1stLevel',\n",
    "                        'sub-{subject_id}/', '???_00??.nii'),\n",
    "             'transform': opj('/data/ds000114/derivatives/fmriprep/', 'sub-{subject_id}', 'anat',\n",
    "                              'sub-{subject_id}_t1w_space-mni152nlin2009casym_warp.h5')}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory=experiment_dir,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', 'sub-')]\n",
    "subjFolders = [('_apply2con%s/' % (i), '') for i in range(number_contrasts)] \n",
    "substitutions.extend(subjFolders)\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specify Workflow (ANTs)\n",
    "\n",
    "Create a workflow and connect the interface nodes and the I/O stream to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Initiation of the ANTs normalization workflow\n",
    "antsflow = Workflow(name='antsflow')\n",
    "antsflow.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect up the ANTs normalization components\n",
    "antsflow.connect([(infosource, selectfiles, [('subject_id', 'subject_id')]),\n",
    "                  (selectfiles, apply2con, [('con', 'input_image'),\n",
    "                                            ('transform', 'transforms')]),\n",
    "                  (apply2con, datasink, [('output_image', 'norm_ants.@con')]),\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize the workflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create ANTs normalization graph\n",
    "antsflow.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(antsflow.base_dir, 'antsflow', 'graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Run the Workflow\n",
    "\n",
    "Now that everything is ready, we can run the ANTs normalization workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "antsflow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "%matplotlib inline\n",
    "subject_id = '02'\n",
    "anatimg = '/data/ds000114/derivatives/fmriprep/mni_icbm152_nlin_asym_09c/1mm_T1.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's chek the normalization of **anatomical** image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_stat_map(\n",
    "   f'/data/ds000114/derivatives/fmriprep/sub-{subject_id}/anat/sub-{subject_id}_t1w_space-mni152nlin2009casym_preproc.nii.gz',\n",
    "    title='anatomy - ANTs (normalized to ICBM152)', bg_img=anatimg,\n",
    "    threshold=200, display_mode='ortho', cut_coords=(-50, 0, -10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And what about the **contrast** images for **Foot > others**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_stat_map(\n",
    "    f'/output/datasink/norm_ants/sub-{subject_id}/con_0005_trans.nii', title='Foot > others - Normed',\n",
    "    bg_img=anatimg, threshold=2, vmax=5, display_mode='ortho', cut_coords=(-39, -37, 56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_glass_brain\n",
    "plot_glass_brain(\n",
    "    f'/output/datasink/norm_ants/sub-{subject_id}/con_0005_trans.nii', colorbar=True,\n",
    "    threshold=3, display_mode='lyrz', black_bg=True, vmax=6, title='contrast5 - ANTs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2nd level analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After we normalized the subjects data into template space, we can now do the group analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "experiment_dir = '/output'\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "\n",
    "# Which contrasts to use for the 2nd-level analysis\n",
    "contrast_list = ['con_0001', 'con_0002', 'con_0003', 'con_0004', 'con_0005']\n",
    "\n",
    "mask = \"/data/ds000114/derivatives/fmriprep/mni_icbm152_nlin_asym_09c/1mm_brainmask.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!tree /output/datasink/2ndLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Gunzip - unzip the mask image\n",
    "gunzip = Node(Gunzip(in_file=mask), name=\"gunzip\")\n",
    "\n",
    "# OneSampleTTestDesign - creates one sample T-Test Design\n",
    "onesamplettestdes = Node(OneSampleTTestDesign(),\n",
    "                         name=\"onesampttestdes\")\n",
    "\n",
    "# EstimateModel - estimates the model\n",
    "level2estimate = Node(EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level2estimate\")\n",
    "\n",
    "# EstimateContrast - estimates group contrast\n",
    "level2conestimate = Node(EstimateContrast(group_contrast=True),\n",
    "                         name=\"level2conestimate\")\n",
    "cont1 = ['Group', 'T', ['mean'], [1]]\n",
    "level2conestimate.inputs.contrasts = [cont1]\n",
    "\n",
    "# Threshold - thresholds contrasts, we use fdr correction\n",
    "level2thresh = Node(Threshold(contrast_index=1,\n",
    "                              use_topo_fdr=True,\n",
    "                              use_fwe_correction=False,\n",
    "                              extent_threshold=0,\n",
    "                              height_threshold=0.005,\n",
    "                              height_threshold_type='p-value',\n",
    "                              extent_fdr_p_threshold=0.05),\n",
    "                    name=\"level2thresh\")\n",
    "\n",
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['contrast_id']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('contrast_id', contrast_list)]\n",
    "\n",
    "# SelectFiles - to grab the data\n",
    "templates = {'cons': opj(output_dir, 'norm_ants', 'sub-*',\n",
    "                         '{contrast_id}_trans.nii')}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory=experiment_dir,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_contrast_id_', '')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initiation of the 2nd-level analysis workflow\n",
    "l2analysis = Workflow(name='ants_l2analysis')\n",
    "l2analysis.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect up the 2nd-level analysis components\n",
    "l2analysis.connect([(infosource, selectfiles, [('contrast_id', 'contrast_id')]),\n",
    "                    (selectfiles, onesamplettestdes, [('cons', 'in_files')]),\n",
    "                    (gunzip, onesamplettestdes, [('out_file',\n",
    "                                                  'explicit_mask_file')]),\n",
    "                    (onesamplettestdes, level2estimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file')]),\n",
    "                    (level2estimate, level2conestimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file'),\n",
    "                                                         ('beta_images',\n",
    "                                                          'beta_images'),\n",
    "                                                         ('residual_image',\n",
    "                                                          'residual_image')]),\n",
    "                    (level2conestimate, level2thresh, [('spm_mat_file',\n",
    "                                                        'spm_mat_file'),\n",
    "                                                       ('spmT_images',\n",
    "                                                        'stat_image'),\n",
    "                                                       ]),\n",
    "                    (level2conestimate, datasink, [('spm_mat_file',\n",
    "                                                    '2ndLevel.@spm_mat'),\n",
    "                                                   ('spmT_images',\n",
    "                                                    '2ndLevel.@T'),\n",
    "                                                   ('con_images',\n",
    "                                                    '2ndLevel.@con')]),\n",
    "                    (level2thresh, datasink, [('thresholded_map',\n",
    "                                               '2ndLevel.@threshold')]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "l2analysis.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "Image(filename='/output/workingdir/ants_l2analysis/graph_detailed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "l2analysis.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nipypecli crash /home/neuro/nipype_tutorial/lection/crash-20200721-181746-neuro-selectfiles.a5-607b7489-d773-4d9c-ae69-49eca16a30d1.pklz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "**Keep in mind, that the group analysis was only done on *`N=7`* subjects, and that we chose a voxel-wise threshold of *`p<0.005`*. Nonetheless, we corrected for multiple comparisons with a cluster-wise FDR threshold of *`p<0.05`*.**\n",
    "\n",
    "So let's first look at the contrast **average**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look at the files we produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!tree /output/datasink/2ndLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "anatimg = '/data/ds000114/derivatives/fmriprep/mni_icbm152_nlin_asym_09c/1mm_T1.nii.gz'\n",
    "plot_stat_map(\n",
    "    '/output/datasink/2ndLevel/con_0001/spmT_0001_thr.nii', title='ants', dim=1,\n",
    "    bg_img=anatimg, threshold=2, vmax=8, display_mode='y', cut_coords=(-45, -30, -15, 0, 15), cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's see other contrast **Foot > others**  using the glass brain plotting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_glass_brain\n",
    "\n",
    "plot_glass_brain(\n",
    "    '/output/datasink/2ndLevel/con_0005/spmT_0001_thr.nii', colorbar=True,\n",
    "    threshold=2, display_mode='lyrz', black_bg=True, vmax=10, title='Foot > others');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple comparison problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we make statistical maps we set a threshold at a given confidence level $\\alpha$ and declare all voxels for which beta is above this  this level as active.\n",
    "Typically our  $H_0$ is that the voxel is not active."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Hypothesis testing](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnmeth.2698/MediaObjects/41592_2013_Article_BFnmeth2698_Fig1_HTML.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The probability that a test will correctly reject $H_0$ is called the power of the test.\n",
    "\n",
    "\n",
    "During fMRI experiments we perform test for each voxel, which means there will be many false active voxels.\n",
    "There are many ways to deal with this problem.\n",
    "\n",
    "How to choose the threshold ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for tr in [2, 4, 5, 7]:\n",
    "    plot_stat_map(\n",
    "        '/output/datasink/2ndLevel/con_0001/spmT_0001.nii', title=f'threshold {tr}', dim=1,\n",
    "        bg_img=anatimg, threshold=tr, vmax=8, display_mode='y', cut_coords=(-45, -30, -15, 0, 15), cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**FWER (family-wize error rate) methods**\n",
    "\n",
    "We control for any false positives $FP$:\n",
    "$$FWER=P(FP \\geq 1)$$\n",
    "$H_0$ is that there is no activation in any of the $V$ voxels.\n",
    "\n",
    "Control for type 1 errors(We wrongly have rejected the $H_0$). \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Bonferoni correction**. The threshold is adjusted as $\\alpha/V$.\n",
    "\n",
    "Decreases too much the probability of correctly rejecting  $H_0$.\n",
    "    \n",
    "The voxels are not completely independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Random field theory** estimates the number of independent statistical tests based upon the spatial correlation, or smoothness.\n",
    "\n",
    "The number of independent comparisons for smoothed data is:\n",
    "     $$V /FWHM^3 $$\n",
    "     \n",
    "where \n",
    "$FWHM$-full width at half maximum\n",
    "\n",
    " At a smoothness of 3 voxels, there would be 1 /27 as many independent comparisons. \n",
    "     \n",
    "The Euler characteristic of the data give us estimation  how many clusters of activity should be found by chance at a given statistical threshold\n",
    "    \n",
    "    \n",
    "FWER methods often give too conservative threshold, oftentimes FDR gives a better threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**FDR (False discovery rate)**\n",
    "\n",
    "Control for the false positives $FP$ among all declared positives $P$.\n",
    "$$FDR=E(FP/P)$$\n",
    "\n",
    "\n",
    "Let's take a look how the popular **Benjamini and Hochberg** FDR procedure work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "#define a treshold level\n",
    "level = 0.05\n",
    "#here we simulate some data to work with\n",
    "#how the treshold is affected by changing signal_to_noise? \n",
    "n_points = 2000\n",
    "signal_to_noise = 0.5\n",
    "noise = np.random.uniform(size=int(n_points*(1-signal_to_noise)))\n",
    "#signal = np.random.uniform(size=int(n_points*signal_to_noise), high=0.001)\n",
    "signal = np.random.beta(a=0.1,b=8, size=int(n_points*signal_to_noise))\n",
    "pvals = np.concatenate([noise, signal])\n",
    "\n",
    "#rank and sort the p values\n",
    "pvals_sortind = np.argsort(pvals)\n",
    "pvals_sorted = pvals[pvals_sortind]\n",
    "n_samples = pvals.shape[0]\n",
    "\n",
    "# the active points are the ones with: p_valule < (rank/n_samples)*level\n",
    "above_tresh = (np.arange(1,n_samples+1)*level/n_samples>pvals_sorted)\n",
    "positive = np.cumsum(above_tresh[::-1])[::-1] #declare positive all points with rank less then the last postive\n",
    "#Let't plot the result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cols = ['red' if p else 'green' for p in positive]\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "\n",
    "ax.scatter(range(n_samples), pvals_sorted, c=cols, marker='.')\n",
    "ax.set_xlabel('ranks')\n",
    "ax.set_ylabel('p values')\n",
    "#lets add Bonferoni treshold for comparison\n",
    "ax.plot([0, n_samples],[0, level], label='BH treshold')#Benjamini and Hochberg\n",
    "plt.axhline(y=level/n_samples, color='black', ls='dashed', alpha = 0.5, label='Bonferoni treshold')\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nibabel\n",
    "#data = np.array(nibabel.load('/output/datasink/2ndLevel/con_0001/spmT_0001.nii').dataobj).flatten()\n",
    "#plt.hist(data, bins=100)\n",
    "#plt.gca().set_ylim([0, 200000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special thanks to Michael Notter for the wonderful [nipype tutorial](https://miykael.github.io/nipype_tutorial/)**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
